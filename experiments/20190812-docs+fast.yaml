user_metadata:
    label_definition:
    team:
    author: 'wen'

cohort_config:
    name: 'test_cohort'
    tender_type:
    query: |
        select td.id_llamado from (
            (select id_llamado from semantic.tenders
            where tipo_procedimiento_codigo = 'CD') as td
          inner join 
            (select id_llamado from semantic.documents
            where is_extractable = true and method != 'pdfminder') as doc
          on td.id_llamado = doc.id_llamado)

label_config:
    name: 'effective_complaint'
    query : 'bool_of_effective_complaints'

features:
    -
        table: 'semantic.tenders'
        columns:
          - log_amt_planned_real_guarani
          - tipo_procedimiento
          - tipo_entidad
          - _objeto_licitacion
          - reception_month
          - reception_day

validation:
    method: 'temporal-folding'
    parameters:
        as_of_date: '2013-01-01'
        train_lag: 'all'
        test_lag: 365
        aod_lag: 182
        blind_gap: 90
        number_of_folds: null
        test_date_limit: '2019-01-31'

evaluation:
    metrics: [recall, precision, f1]
    parameters: 
        at%: [5, 10, 15, 20,  30,  40,  50,  70,  90]
        lower_bound: 1
        upper_bound: 30
    groups:
        CD: director1
        CO: director2
        LPN: director3
        LPI: director3
        LC: director3
        CE: director3

model_config:
    random_seed: 22
    max_seconds: 300 # 5 minutes max runtime
    errors: false
    
textprocessing:
    tfidf:
        max_df: 1.0
        max_features: 500
        #ngram_range: (1, 1)
        norm: 'l2'

approaches:
    -
      approach_name: 'higher_than_x'
      file_path: 'heuristic_approach.py'
      preprocessors: []
      hyperparameters:
        heuristic:
          params:
            sorting:
              -
                column_name: log_amt_planned_real_guarani
                higher: true
    # -
    #     approach_name: 'ada_boost'
    #     file_path: 'generic_approach.py'
    #     preprocessors: ['StandardScaler', 'OneHotEncoder']
    #     hyperparameters:
    #       algorithm:
    #       - SAMME
    #       - SAMME.R
    #       n_estimators:
    #       - 1
    #       - 10
    #       - 10000
    -
        approach_name: 'decision_tree'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          criterion:
          - gini
          - entropy
          max_depth:
          - 1
          - 5
          - 10
          - 50
          max_features:
          - null
          min_samples_split:
          - 2
          - 5
          - 10
    -
        approach_name: 'extra_trees'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          criterion:
          - gini
          # - entropy
          max_depth:
          # - 1
          # - 5
          - 10
          max_features:
          - sqrt
          - log2
          min_samples_split:
          - 2
          # - 5
          n_estimators:
          # - 1
          - 10
          # - 100
          n_jobs:
          - -1
    # -
    #     approach_name: 'gradient_boosting'
    #     file_path: 'generic_approach.py'
    #     preprocessors: ['StandardScaler', 'OneHotEncoder']
    #     hyperparameters:
    #       learning_rate:
    #       - 0.001
    #       - 0.01
    #       - 0.05
    #       - 0.1
    #       - 0.5
    #       max_depth:
    #       - 1
    #       - 3
    #       - 5
    #       - 20
    #       n_estimators:
    #       - 1
    #       - 10
    #       - 500
    #       subsample:
    #       - 0.1
    #       - 0.5
    #       - 1.0

    -
        approach_name: 'knn'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          algorithm:
          - auto
          # - ball_tree
          # - kd_tree
          n_neighbors:
          # - 1
          # - 5
          - 10
          # - 50
          weights:
          # - uniform
          - distance
    -
        approach_name: 'logistic_regression'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          C:
          - 1.0e-05
          - 0.0001
          - 0.001
          - 1
          - 10
          penalty:
          - l1
          - l2
    -
        approach_name: 'random_forest'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          max_depth:
          # - 1
          # - 5
          - 10
          max_features:
          - sqrt
          # - log2
          min_samples_split:
          - 2
          # - 5
          # - 10
          n_estimators:
          # - 1
          # - 10
          - 100
          n_jobs:
          - -1
    -
        approach_name: 'svm'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          C:
          # - 1.0e-05
          - 0.0001
          # - 0.001
          - 0.01
          # - 0.1
          - 1
          # - 10
          kernel:
          - linear
    -
        approach_name: 'lgbm'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          max_depth:
            # - 5
            # - 10
            - 50
          boosting_type:
            - 'gbdt'
            # - 'dart'
            # - 'goss'
            # - 'rf'
          min_child_weight:
            # - 1.0e-5
            - 1.0e-2
            - 1
            # - 1.0e2
          verbose:
            - -1
    -
        approach_name: 'xgb'
        file_path: 'generic_approach.py'
        preprocessors: ['StandardScaler', 'OneHotEncoder']
        hyperparameters:
          max_depth:
            # - 3
            # - 5
            - 10
          min_child_weight:
            - 1.0e-5
            # - 1.0e-2
            - 1
            - 1.0e2
          scale_pos_weight:
            # - 1
            # - 5
            - 10
          learning_rate:
            # - 0.05
            - 1
            - 0.3

