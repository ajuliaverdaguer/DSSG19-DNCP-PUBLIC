# Thresholds for positive class (absolutes top k and top k %)
score_thresholds:
    rank_abs: [200]
    rank_pct: [0.01, 0.02, 0.05, 0.10] #needs to be a float between 0 and 1

#available options: "predefined", "majority" and "min_metric"
ref_groups_method: "majority"

# if "predefined" is selected, you need to provide the column:value pairs to be used as reference
#ref_groups:
  #"attribute_1": "<0.30"

# fairness threshold to be used for assessing fairness
fairness_threshold: 0.7

# available fairness_measeure "Impact Parity", "Statistical Parity", "FPR Parity", "FDR Parity", "FNR Parity", "FOR Parity"
fairness_measures: ["Statistical Parity", "FOR Parity"]

# to connect to a database instead of using "--input <filename>", use the db key, credentials, and input_query
db:
    db_credentials:
        host: your_host
        database: your_db
        user: your_user
        password: your_pass
        port: 5432


    # the input query should return a table with score, label_value columns and then each attribute you want to use for bias analysis
    input_query: "select id, score, label_value, attribute_1, attribute_2 from results.predictions left join ..."

    # the output schema is optional, default=public
    output_schema: test_results
    output_table: aequitas_group
